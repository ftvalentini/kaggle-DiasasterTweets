{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "01-nn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9Le-jglsYKk2",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CB6-ejuyV8Vd",
        "colab": {}
      },
      "source": [
        "### Do just once In google Colab left pane: ###\n",
        "# Upload into Files:\n",
        "  # neural.zip\n",
        "  # data.zip\n",
        "  # helpers_models.py\n",
        "  # helpers_strings.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YPziU7Hj085",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### run just once: ### -- downloads tardan 15 min aprox\n",
        "# !unzip data.zip\n",
        "# !wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "# !wget http://nlp.stanford.edu/data/glove.twitter.27B.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uyLUfbLEGEb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "0626184b-2781-4b15-fc5d-027c993b830a"
      },
      "source": [
        "!unzip -n glove.6B.zip\n",
        "!unzip -n glove.twitter.27B.zip\n",
        "!unzip -o neural.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "Archive:  glove.twitter.27B.zip\n",
            "Archive:  neural.zip\n",
            " extracting: neural/__init__.py      \n",
            "  inflating: neural/architectures.py  \n",
            " extracting: neural/core/__init__.py  \n",
            "  inflating: neural/core/helpers.py  \n",
            "  inflating: neural/core/training.py  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O6-2SqfX8wlw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9857bbe-d101-4fee-df29-e75308df0ed1"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import helpers_models as hm\n",
        "\n",
        "from neural.architectures import build_gru\n",
        "from neural.core.training import full_nn"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BAdzPXU_evrp",
        "colab": {}
      },
      "source": [
        "RUN_SANITY = False\n",
        "NEW_RANDOM_SPLIT = True\n",
        "LOAD_PRETRAINED_VECS = True # False no genera el dict de embeddings (xq tarda unos min)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yfkq2_8DDRnq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "31679b28-07a3-4fef-994f-ebe972a74952"
      },
      "source": [
        "if NEW_RANDOM_SPLIT:\n",
        "  semilla = np.random.randint(1,9999)\n",
        "else:\n",
        "  semilla = 800\n",
        "rng = np.random.RandomState(semilla)\n",
        "print(semilla)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CN4yULG6AM7X",
        "colab": {}
      },
      "source": [
        "datos_raw = hm.read_tagged_data()\n",
        "datos = hm.clean_tagged_data(datos_raw)\n",
        "X = datos['text']\n",
        "y = datos['target']\n",
        "X_train, X_val, y_train, y_val = hm.split_data(X, y, 0.2, rng)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hJ7KvjQl0SW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "66feb633-4cfa-46d3-aadf-be18ed43cae5"
      },
      "source": [
        "if LOAD_PRETRAINED_VECS:\n",
        "  # load pretrained embeddings glove_twitter\n",
        "  embeddings_twitter = {}\n",
        "  with open('glove.twitter.27B.200d.txt') as f:\n",
        "    for line in f:\n",
        "      word, coefs = line.split(maxsplit=1)\n",
        "      coefs = np.fromstring(coefs, 'f', sep=' ')\n",
        "      embeddings_twitter[word] = coefs\n",
        "  # load pretrained embeddings glove_wiki\n",
        "  embeddings_wiki = {}\n",
        "  with open('glove.6B.300d.txt') as f:\n",
        "    for line in f:\n",
        "      word, coefs = line.split(maxsplit=1)\n",
        "      coefs = np.fromstring(coefs, 'f', sep=' ')\n",
        "      embeddings_wiki[word] = coefs"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR! Session/line number was not unique in database. History logging moved to new session 68\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sFbpUNT16P6c",
        "colab": {}
      },
      "source": [
        "### GRU sanity check ###\n",
        "if RUN_SANITY:\n",
        "  param_tokenizer = dict(\n",
        "                      vocab_size=None\n",
        "                      ,pad_type='pre'\n",
        "                      ,seq_maxlen=100\n",
        "                      )\n",
        "  param_nn = dict(\n",
        "                        optimizer='adam'\n",
        "                        ,learn_rate=1e-5\n",
        "                        ,l2_strength=0.0\n",
        "                        ,decay_strength=0.0\n",
        "                        ,momentum=None          \n",
        "                        ,embeddings=embeddings_twitter\n",
        "                        ,initializer='he_uniform'  \n",
        "                  )\n",
        "  param_train = dict(\n",
        "                        model_id='sanity'\n",
        "                        ,epochs=20\n",
        "                        ,batch_size=32\n",
        "                        ,early_stopping_n=999999\n",
        "                        ,decay_factor=0.0\n",
        "                        ,decay_patience_n=999999\n",
        "                        ,sanity_check_n=20\n",
        "                        ,verbose=0\n",
        "                    )\n",
        "  param_sanity = dict(**param_tokenizer, **param_nn, **param_train)\n",
        "  mod_check = full_nn(\n",
        "                build_gru, X_train, y_train, X_val, y_val, **param_sanity\n",
        "                ) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bbbNGTfgAi3P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c04d476a-b597-43f8-fbad-93142a156d00"
      },
      "source": [
        "# NN parameters\n",
        "param_tokenizer = dict(\n",
        "                      vocab_size=None\n",
        "                      ,pad_type='pre'\n",
        "                      ,seq_maxlen=100\n",
        "                      )\n",
        "param_nn = dict(\n",
        "                      optimizer='adam'\n",
        "                      ,learn_rate=1e-5\n",
        "                      ,l2_strength=0.01\n",
        "                      ,decay_strength=0.0\n",
        "                      ,momentum=None          \n",
        "                      ,embeddings=embeddings_wiki\n",
        "                      ,initializer='he_uniform'\n",
        "                )\n",
        "param_train = dict(\n",
        "                      model_id='GloveWiki01'\n",
        "                      ,epochs=200\n",
        "                      ,batch_size=16\n",
        "                      ,early_stopping_n=20\n",
        "                      ,decay_factor=0.8\n",
        "                      ,decay_patience_n=10\n",
        "                      ,sanity_check_n=None\n",
        "                      ,verbose=2\n",
        "                  )\n",
        "param = dict(**param_tokenizer, **param_nn, **param_train)\n",
        "\n",
        "# Training NN\n",
        "mod = full_nn(build_gru, X_train, y_train, X_val, y_val, **param)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 6002 samples, validate on 1501 samples\n",
            "Epoch 1/200\n",
            " - 6s - loss: 37.7300 - acc: 0.6140 - val_loss: 36.3572 - val_acc: 0.6696\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.66955, saving model to GloveWiki01_best.hdf5\n",
            "- val_f1: 0.5811 - val_rec: 0.5350 - val_prec: 0.6359 \n",
            "Epoch 2/200\n",
            " - 4s - loss: 35.0733 - acc: 0.6533 - val_loss: 33.7922 - val_acc: 0.6869\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.66955 to 0.68688, saving model to GloveWiki01_best.hdf5\n",
            "- val_f1: 0.6185 - val_rec: 0.5925 - val_prec: 0.6469 \n",
            "Epoch 3/200\n",
            " - 4s - loss: 32.5852 - acc: 0.6979 - val_loss: 31.3832 - val_acc: 0.7235\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.68688 to 0.72352, saving model to GloveWiki01_best.hdf5\n",
            "- val_f1: 0.6765 - val_rec: 0.6750 - val_prec: 0.6781 \n",
            "Epoch 4/200\n",
            " - 4s - loss: 30.2395 - acc: 0.7429 - val_loss: 29.1105 - val_acc: 0.7535\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.72352 to 0.75350, saving model to GloveWiki01_best.hdf5\n",
            "- val_f1: 0.7021 - val_rec: 0.6781 - val_prec: 0.7279 \n",
            "Epoch 5/200\n",
            " - 4s - loss: 28.0334 - acc: 0.7732 - val_loss: 26.9921 - val_acc: 0.7728\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.75350 to 0.77282, saving model to GloveWiki01_best.hdf5\n",
            "- val_f1: 0.7156 - val_rec: 0.6672 - val_prec: 0.7716 \n",
            "Epoch 6/200\n",
            " - 4s - loss: 25.9969 - acc: 0.7961 - val_loss: 25.0412 - val_acc: 0.7868\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.77282 to 0.78681, saving model to GloveWiki01_best.hdf5\n",
            "- val_f1: 0.7265 - val_rec: 0.6610 - val_prec: 0.8065 \n",
            "Epoch 7/200\n",
            " - 4s - loss: 24.1151 - acc: 0.8064 - val_loss: 23.2404 - val_acc: 0.7921\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.78681 to 0.79214, saving model to GloveWiki01_best.hdf5\n",
            "- val_f1: 0.7148 - val_rec: 0.6081 - val_prec: 0.8670 \n",
            "Epoch 8/200\n",
            " - 4s - loss: 22.3649 - acc: 0.8114 - val_loss: 21.5422 - val_acc: 0.8021\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.79214 to 0.80213, saving model to GloveWiki01_best.hdf5\n",
            "- val_f1: 0.7523 - val_rec: 0.7014 - val_prec: 0.8112 \n",
            "Epoch 9/200\n",
            " - 4s - loss: 20.7300 - acc: 0.8144 - val_loss: 19.9741 - val_acc: 0.7975\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.80213\n",
            "- val_f1: 0.7211 - val_rec: 0.6112 - val_prec: 0.8792 \n",
            "Epoch 10/200\n",
            " - 4s - loss: 19.2030 - acc: 0.8189 - val_loss: 18.4954 - val_acc: 0.8028\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.80213 to 0.80280, saving model to GloveWiki01_best.hdf5\n",
            "- val_f1: 0.7333 - val_rec: 0.6330 - val_prec: 0.8715 \n",
            "Epoch 11/200\n",
            " - 4s - loss: 17.7756 - acc: 0.8199 - val_loss: 17.1169 - val_acc: 0.8055\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.80280 to 0.80546, saving model to GloveWiki01_best.hdf5\n",
            "- val_f1: 0.7365 - val_rec: 0.6345 - val_prec: 0.8774 \n",
            "Epoch 12/200\n",
            " - 4s - loss: 16.4385 - acc: 0.8216 - val_loss: 15.8272 - val_acc: 0.8048\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.80546\n",
            "- val_f1: 0.7358 - val_rec: 0.6345 - val_prec: 0.8755 \n",
            "Epoch 13/200\n",
            " - 4s - loss: 15.1900 - acc: 0.8214 - val_loss: 14.6136 - val_acc: 0.8035\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.80546\n",
            "- val_f1: 0.7472 - val_rec: 0.6781 - val_prec: 0.8321 \n",
            "Epoch 14/200\n",
            " - 4s - loss: 14.0224 - acc: 0.8239 - val_loss: 13.4881 - val_acc: 0.8035\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.80546\n",
            "- val_f1: 0.7433 - val_rec: 0.6641 - val_prec: 0.8439 \n",
            "Epoch 15/200\n",
            " - 4s - loss: 12.9321 - acc: 0.8244 - val_loss: 12.4372 - val_acc: 0.8028\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.80546\n",
            "- val_f1: 0.7508 - val_rec: 0.6936 - val_prec: 0.8183 \n",
            "Epoch 16/200\n",
            " - 4s - loss: 11.9148 - acc: 0.8272 - val_loss: 11.4656 - val_acc: 0.8095\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.80546 to 0.80946, saving model to GloveWiki01_best.hdf5\n",
            "- val_f1: 0.7409 - val_rec: 0.6361 - val_prec: 0.8872 \n",
            "Epoch 17/200\n",
            " - 4s - loss: 10.9714 - acc: 0.8251 - val_loss: 10.5507 - val_acc: 0.8061\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.80946\n",
            "- val_f1: 0.7418 - val_rec: 0.6501 - val_prec: 0.8636 \n",
            "Epoch 18/200\n",
            " - 4s - loss: 10.0935 - acc: 0.8267 - val_loss: 9.7052 - val_acc: 0.8055\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.80946\n",
            "- val_f1: 0.7430 - val_rec: 0.6563 - val_prec: 0.8560 \n",
            "Epoch 19/200\n",
            " - 4s - loss: 9.2799 - acc: 0.8297 - val_loss: 8.9218 - val_acc: 0.8041\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.80946\n",
            "- val_f1: 0.7500 - val_rec: 0.6858 - val_prec: 0.8274 \n",
            "Epoch 20/200\n",
            " - 4s - loss: 8.5262 - acc: 0.8294 - val_loss: 8.2012 - val_acc: 0.8081\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.80946\n",
            "- val_f1: 0.7620 - val_rec: 0.7170 - val_prec: 0.8131 \n",
            "Epoch 21/200\n",
            " - 4s - loss: 7.8324 - acc: 0.8327 - val_loss: 7.5349 - val_acc: 0.8048\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.80946\n",
            "- val_f1: 0.7463 - val_rec: 0.6703 - val_prec: 0.8418 \n",
            "Epoch 22/200\n",
            " - 4s - loss: 7.1937 - acc: 0.8357 - val_loss: 6.9239 - val_acc: 0.8021\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.80946\n",
            "- val_f1: 0.7446 - val_rec: 0.6734 - val_prec: 0.8327 \n",
            "Epoch 23/200\n",
            " - 4s - loss: 6.6072 - acc: 0.8377 - val_loss: 6.3713 - val_acc: 0.7995\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.80946\n",
            "- val_f1: 0.7598 - val_rec: 0.7403 - val_prec: 0.7803 \n",
            "Epoch 24/200\n",
            " - 4s - loss: 6.0747 - acc: 0.8364 - val_loss: 5.8599 - val_acc: 0.8041\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.80946\n",
            "- val_f1: 0.7407 - val_rec: 0.6532 - val_prec: 0.8554 \n",
            "Epoch 25/200\n",
            " - 4s - loss: 5.5874 - acc: 0.8344 - val_loss: 5.3942 - val_acc: 0.8061\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.80946\n",
            "- val_f1: 0.7540 - val_rec: 0.6936 - val_prec: 0.8259 \n",
            "Epoch 26/200\n",
            " - 4s - loss: 5.1448 - acc: 0.8379 - val_loss: 4.9757 - val_acc: 0.8068\n",
            "\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 8.999999772640877e-06.\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.80946\n",
            "- val_f1: 0.7447 - val_rec: 0.6579 - val_prec: 0.8580 \n",
            "Epoch 27/200\n",
            " - 4s - loss: 4.7626 - acc: 0.8397 - val_loss: 4.6388 - val_acc: 0.8041\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.80946\n",
            "- val_f1: 0.7327 - val_rec: 0.6267 - val_prec: 0.8818 \n",
            "Epoch 28/200\n",
            " - 4s - loss: 4.4321 - acc: 0.8377 - val_loss: 4.3149 - val_acc: 0.8075\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.80946\n",
            "- val_f1: 0.7524 - val_rec: 0.6827 - val_prec: 0.8378 \n",
            "Epoch 29/200\n",
            " - 4s - loss: 4.1322 - acc: 0.8367 - val_loss: 4.0330 - val_acc: 0.8041\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.80946\n",
            "- val_f1: 0.7421 - val_rec: 0.6579 - val_prec: 0.8511 \n",
            "Epoch 30/200\n",
            " - 4s - loss: 3.8612 - acc: 0.8392 - val_loss: 3.7717 - val_acc: 0.8041\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.80946\n",
            "- val_f1: 0.7517 - val_rec: 0.6921 - val_prec: 0.8226 \n",
            "Epoch 31/200\n",
            " - 4s - loss: 3.6131 - acc: 0.8389 - val_loss: 3.5504 - val_acc: 0.8048\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.80946\n",
            "- val_f1: 0.7334 - val_rec: 0.6267 - val_prec: 0.8838 \n",
            "Epoch 32/200\n",
            " - 4s - loss: 3.3920 - acc: 0.8386 - val_loss: 3.3295 - val_acc: 0.8061\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.80946\n",
            "- val_f1: 0.7445 - val_rec: 0.6594 - val_prec: 0.8548 \n",
            "Epoch 33/200\n",
            " - 4s - loss: 3.1894 - acc: 0.8392 - val_loss: 3.1367 - val_acc: 0.8108\n",
            "\n",
            "Epoch 00033: val_acc improved from 0.80946 to 0.81079, saving model to GloveWiki01_best.hdf5\n",
            "- val_f1: 0.7560 - val_rec: 0.6843 - val_prec: 0.8445 \n",
            "Epoch 34/200\n",
            " - 4s - loss: 3.0080 - acc: 0.8407 - val_loss: 2.9685 - val_acc: 0.8061\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.81079\n",
            "- val_f1: 0.7427 - val_rec: 0.6532 - val_prec: 0.8607 \n",
            "Epoch 35/200\n",
            " - 4s - loss: 2.8465 - acc: 0.8392 - val_loss: 2.8304 - val_acc: 0.8095\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.81079\n",
            "- val_f1: 0.7357 - val_rec: 0.6190 - val_prec: 0.9066 \n",
            "Epoch 36/200\n",
            " - 4s - loss: 2.6992 - acc: 0.8419 - val_loss: 2.6776 - val_acc: 0.8095\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.81079\n",
            "- val_f1: 0.7504 - val_rec: 0.6687 - val_prec: 0.8549 \n",
            "Epoch 37/200\n",
            " - 4s - loss: 2.5705 - acc: 0.8412 - val_loss: 2.5534 - val_acc: 0.8081\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.81079\n",
            "- val_f1: 0.7500 - val_rec: 0.6719 - val_prec: 0.8487 \n",
            "Epoch 38/200\n",
            " - 4s - loss: 2.4534 - acc: 0.8426 - val_loss: 2.4440 - val_acc: 0.8061\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.81079\n",
            "- val_f1: 0.7459 - val_rec: 0.6641 - val_prec: 0.8506 \n",
            "Epoch 39/200\n",
            " - 4s - loss: 2.3484 - acc: 0.8434 - val_loss: 2.3564 - val_acc: 0.8055\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.81079\n",
            "- val_f1: 0.7355 - val_rec: 0.6314 - val_prec: 0.8807 \n",
            "Epoch 40/200\n",
            " - 4s - loss: 2.2558 - acc: 0.8419 - val_loss: 2.2570 - val_acc: 0.8061\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.81079\n",
            "- val_f1: 0.7532 - val_rec: 0.6905 - val_prec: 0.8284 \n",
            "Epoch 41/200\n",
            " - 4s - loss: 2.1734 - acc: 0.8437 - val_loss: 2.1852 - val_acc: 0.8075\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.81079\n",
            "- val_f1: 0.7427 - val_rec: 0.6485 - val_prec: 0.8688 \n",
            "Epoch 42/200\n",
            " - 4s - loss: 2.0985 - acc: 0.8446 - val_loss: 2.1103 - val_acc: 0.8061\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.81079\n",
            "- val_f1: 0.7467 - val_rec: 0.6672 - val_prec: 0.8478 \n",
            "Epoch 43/200\n",
            " - 4s - loss: 2.0306 - acc: 0.8441 - val_loss: 2.0498 - val_acc: 0.8075\n",
            "\n",
            "Epoch 00043: ReduceLROnPlateau reducing learning rate to 8.099999467958696e-06.\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.81079\n",
            "- val_f1: 0.7454 - val_rec: 0.6579 - val_prec: 0.8598 \n",
            "Epoch 44/200\n",
            " - 4s - loss: 1.9719 - acc: 0.8471 - val_loss: 2.0031 - val_acc: 0.8068\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.81079\n",
            "- val_f1: 0.7392 - val_rec: 0.6392 - val_prec: 0.8763 \n",
            "Epoch 45/200\n",
            " - 4s - loss: 1.9202 - acc: 0.8464 - val_loss: 1.9481 - val_acc: 0.8081\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.81079\n",
            "- val_f1: 0.7504 - val_rec: 0.6734 - val_prec: 0.8474 \n",
            "Epoch 46/200\n",
            " - 4s - loss: 1.8748 - acc: 0.8432 - val_loss: 1.9088 - val_acc: 0.8081\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.81079\n",
            "- val_f1: 0.7433 - val_rec: 0.6485 - val_prec: 0.8706 \n",
            "Epoch 47/200\n",
            " - 4s - loss: 1.8307 - acc: 0.8444 - val_loss: 1.8627 - val_acc: 0.8068\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.81079\n",
            "- val_f1: 0.7487 - val_rec: 0.6719 - val_prec: 0.8454 \n",
            "Epoch 48/200\n",
            " - 4s - loss: 1.7907 - acc: 0.8431 - val_loss: 1.8308 - val_acc: 0.8068\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.81079\n",
            "- val_f1: 0.7411 - val_rec: 0.6454 - val_prec: 0.8700 \n",
            "Epoch 49/200\n",
            " - 4s - loss: 1.7540 - acc: 0.8441 - val_loss: 1.7878 - val_acc: 0.8101\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.81079\n",
            "- val_f1: 0.7570 - val_rec: 0.6905 - val_prec: 0.8377 \n",
            "Epoch 50/200\n",
            " - 4s - loss: 1.7186 - acc: 0.8479 - val_loss: 1.7559 - val_acc: 0.8101\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.81079\n",
            "- val_f1: 0.7511 - val_rec: 0.6687 - val_prec: 0.8566 \n",
            "Epoch 51/200\n",
            " - 4s - loss: 1.6864 - acc: 0.8462 - val_loss: 1.7225 - val_acc: 0.8081\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.81079\n",
            "- val_f1: 0.7538 - val_rec: 0.6858 - val_prec: 0.8368 \n",
            "Epoch 52/200\n",
            " - 4s - loss: 1.6543 - acc: 0.8451 - val_loss: 1.6975 - val_acc: 0.8095\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.81079\n",
            "- val_f1: 0.7469 - val_rec: 0.6563 - val_prec: 0.8665 \n",
            "Epoch 53/200\n",
            " - 4s - loss: 1.6258 - acc: 0.8472 - val_loss: 1.6674 - val_acc: 0.8068\n",
            "\n",
            "Epoch 00053: ReduceLROnPlateau reducing learning rate to 7.28999984858092e-06.\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.81079\n",
            "- val_f1: 0.7465 - val_rec: 0.6641 - val_prec: 0.8523 \n",
            "Epoch 54/200\n",
            " - 4s - loss: 1.5981 - acc: 0.8482 - val_loss: 1.6425 - val_acc: 0.8068\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.81079\n",
            "- val_f1: 0.7483 - val_rec: 0.6703 - val_prec: 0.8468 \n",
            "Epoch 55/200\n",
            " - 4s - loss: 1.5732 - acc: 0.8459 - val_loss: 1.6200 - val_acc: 0.8095\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.81079\n",
            "- val_f1: 0.7539 - val_rec: 0.6812 - val_prec: 0.8439 \n",
            "Epoch 56/200\n",
            " - 4s - loss: 1.5518 - acc: 0.8472 - val_loss: 1.6021 - val_acc: 0.8075\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.81079\n",
            "- val_f1: 0.7440 - val_rec: 0.6532 - val_prec: 0.8642 \n",
            "Epoch 57/200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XWMZQJghCTav",
        "colab": {}
      },
      "source": [
        "# Agregar RandonSearch (o bayesian para los aventureros)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
