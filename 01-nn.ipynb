{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "01-nn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9Le-jglsYKk2",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CB6-ejuyV8Vd",
        "colab": {}
      },
      "source": [
        "### Do just once In google Colab left pane: ###\n",
        "# Upload into Files:\n",
        "  # neural.zip\n",
        "  # data.zip\n",
        "  # helpers_models.py\n",
        "  # helpers_strings.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YPziU7Hj085",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### run just once: ### -- downloads tardan 15 min aprox\n",
        "# !unzip data.zip\n",
        "# !wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "# !wget http://nlp.stanford.edu/data/glove.twitter.27B.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uyLUfbLEGEb9",
        "colab": {}
      },
      "source": [
        "!unzip -n glove.6B.zip\n",
        "!unzip -n glove.twitter.27B.zip\n",
        "!unzip -o neural.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O6-2SqfX8wlw",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import helpers_models as hm\n",
        "\n",
        "from neural.architectures import build_gru\n",
        "from neural.core.training import full_nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BAdzPXU_evrp",
        "colab": {}
      },
      "source": [
        "RUN_SANITY = False\n",
        "NEW_RANDOM_SPLIT = True\n",
        "LOAD_PRETRAINED_VECS = True # False no genera el dict de embeddings (xq tarda unos min)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yfkq2_8DDRnq",
        "colab": {}
      },
      "source": [
        "if NEW_RANDOM_SPLIT:\n",
        "  semilla = np.random.randint(1,9999)\n",
        "else:\n",
        "  semilla = 800\n",
        "rng = np.random.RandomState(semilla)\n",
        "print(semilla)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CN4yULG6AM7X",
        "colab": {}
      },
      "source": [
        "datos_raw = hm.read_tagged_data()\n",
        "datos = hm.clean_tagged_data(datos_raw)\n",
        "X = datos['text']\n",
        "y = datos['target']\n",
        "X_train, X_val, y_train, y_val = hm.split_data(X, y, 0.2, rng)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hJ7KvjQl0SW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if LOAD_PRETRAINED_VECS:\n",
        "  # load pretrained embeddings glove_twitter\n",
        "  embeddings_twitter = {}\n",
        "  with open('glove.twitter.27B.200d.txt') as f:\n",
        "    for line in f:\n",
        "      word, coefs = line.split(maxsplit=1)\n",
        "      coefs = np.fromstring(coefs, 'f', sep=' ')\n",
        "      embeddings_twitter[word] = coefs\n",
        "  # load pretrained embeddings glove_wiki\n",
        "  embeddings_wiki = {}\n",
        "  with open('glove.6B.300d.txt') as f:\n",
        "    for line in f:\n",
        "      word, coefs = line.split(maxsplit=1)\n",
        "      coefs = np.fromstring(coefs, 'f', sep=' ')\n",
        "      embeddings_wiki[word] = coefs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sFbpUNT16P6c",
        "colab": {}
      },
      "source": [
        "### GRU sanity check ###\n",
        "if RUN_SANITY:\n",
        "  param_tokenizer = dict(\n",
        "                      vocab_size=None\n",
        "                      ,pad_type='pre'\n",
        "                      ,seq_maxlen=100\n",
        "                      )\n",
        "  param_nn = dict(\n",
        "                        optimizer='adam'\n",
        "                        ,learn_rate=1e-5\n",
        "                        ,l2_strength=0.0\n",
        "                        ,decay_strength=0.0\n",
        "                        ,momentum=None          \n",
        "                        ,embeddings=embeddings_twitter\n",
        "                        ,initializer='he_uniform'  \n",
        "                  )\n",
        "  param_train = dict(\n",
        "                        model_id='sanity'\n",
        "                        ,epochs=20\n",
        "                        ,batch_size=32\n",
        "                        ,early_stopping_n=999999\n",
        "                        ,decay_factor=0.0\n",
        "                        ,decay_patience_n=999999\n",
        "                        ,sanity_check_n=20\n",
        "                        ,verbose=0\n",
        "                    )\n",
        "  param_sanity = dict(**param_tokenizer, **param_nn, **param_train)\n",
        "  mod_check = full_nn(\n",
        "                build_gru, X_train, y_train, X_val, y_val, **param_sanity\n",
        "                ) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bbbNGTfgAi3P",
        "colab": {}
      },
      "source": [
        "# NN parameters\n",
        "param_tokenizer = dict(\n",
        "                      vocab_size=None\n",
        "                      ,pad_type='pre'\n",
        "                      ,seq_maxlen=100\n",
        "                      )\n",
        "param_nn = dict(\n",
        "                      optimizer='adam'\n",
        "                      ,learn_rate=1e-5\n",
        "                      ,l2_strength=0.01\n",
        "                      ,decay_strength=0.0\n",
        "                      ,momentum=None          \n",
        "                      ,embeddings=embeddings_wiki\n",
        "                      ,initializer='he_uniform'\n",
        "                )\n",
        "param_train = dict(\n",
        "                      model_id='GloveWiki01'\n",
        "                      ,epochs=200\n",
        "                      ,batch_size=16\n",
        "                      ,early_stopping_n=20\n",
        "                      ,decay_factor=0.8\n",
        "                      ,decay_patience_n=10\n",
        "                      ,sanity_check_n=None\n",
        "                      ,verbose=2\n",
        "                  )\n",
        "param = dict(**param_tokenizer, **param_nn, **param_train)\n",
        "\n",
        "# Training NN\n",
        "mod = full_nn(build_gru, X_train, y_train, X_val, y_val, **param)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XWMZQJghCTav",
        "colab": {}
      },
      "source": [
        "# Agregar RandonSearch (o bayesian para los aventureros)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}